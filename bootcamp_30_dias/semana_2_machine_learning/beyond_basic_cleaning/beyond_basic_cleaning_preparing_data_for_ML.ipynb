{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "923a6b88",
   "metadata": {},
   "source": [
    "# Beyond Basic Cleaning: Preparando Dados para Machine Learning\n",
    "\r\n",
    "Noteboo que terá alterações pessoais para acompanhar o original acesse os links dos readme.\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b68745",
   "metadata": {},
   "source": [
    "## 1) CLoad the dataset\n",
    "We'll start with a deliberately **messy** dataset that contains missing values, outliers, and inconsistent date formats.\n",
    "\n",
    "## 1) Carregar o dataset\r\n",
    "Começaremos com um dataset propositalmente **bagunçado**, que contém valores ausentes, outliers e formatos de data inconsistentes.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42511183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>event_date</th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>gender</th>\n",
       "      <th>region</th>\n",
       "      <th>purchases</th>\n",
       "      <th>category</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-04-13</td>\n",
       "      <td>34.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Female</td>\n",
       "      <td>East</td>\n",
       "      <td>2.0</td>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-12-15</td>\n",
       "      <td>40.0</td>\n",
       "      <td>54770.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>East</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2023-09-28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85399.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>East</td>\n",
       "      <td>2.0</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2023-04-17</td>\n",
       "      <td>44.0</td>\n",
       "      <td>52703.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2023-03-13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53504.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>North</td>\n",
       "      <td>7.0</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  event_date   age   income  gender region  purchases category  churn\n",
       "0   1  2023-04-13  34.0      NaN  Female   East        2.0        D      0\n",
       "1   2  2023-12-15  40.0  54770.0    Male   East        2.0      NaN      1\n",
       "2   3  2023-09-28   NaN  85399.0  Female   East        2.0        B      0\n",
       "3   4  2023-04-17  44.0  52703.0    Male    NaN        NaN        B      1\n",
       "4   5  2023-03-13   NaN  53504.0     NaN  North        7.0        B      0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('ml_prep_demo_raw.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdde0897-50ae-4606-9916-dd1484e175c1",
   "metadata": {},
   "source": [
    "```py\n",
    "import warnings\n",
    "\n",
    " warnings.filterwarnings(\"ignore\")\n",
    "```\n",
    "\n",
    "A importação e código acima faz com que todos os warnings do Python sejam suprimidos durante a execução do código.\n",
    "\n",
    "Mesmo sendo um material didático acho sensato o aluno(a) já ver os erros, para no momento não traver ou se assustar e não saber o que fazer.\n",
    "claro que é a minha opnião pessoal.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e287bb79",
   "metadata": {},
   "source": [
    "## 2) Quick EDA & data types\n",
    "Check shape, nulls, and dtypes to see what we’re dealing with.\n",
    "\n",
    "## 2) EDA rápido e tipos de dados\r\n",
    "Vamos verificar o shape, valores nulos e dtypes para entender com o que estamos lidando.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e80e3448",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500, 9)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1500 entries, 0 to 1499\n",
      "Data columns (total 9 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   id          1500 non-null   int64  \n",
      " 1   event_date  1500 non-null   object \n",
      " 2   age         1405 non-null   float64\n",
      " 3   income      1396 non-null   float64\n",
      " 4   gender      1379 non-null   object \n",
      " 5   region      1414 non-null   object \n",
      " 6   purchases   1397 non-null   float64\n",
      " 7   category    1396 non-null   object \n",
      " 8   churn       1500 non-null   int64  \n",
      "dtypes: float64(3), int64(2), object(4)\n",
      "memory usage: 105.6+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "gender        0.080667\n",
       "income        0.069333\n",
       "category      0.069333\n",
       "purchases     0.068667\n",
       "age           0.063333\n",
       "region        0.057333\n",
       "id            0.000000\n",
       "event_date    0.000000\n",
       "churn         0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape) # mostra de forma resumida linha, coluna\n",
    "df.info() # informações básicas do dataset\n",
    "df.isna().mean().sort_values(ascending=False)  # média de valores nulos por coluna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178cbf9f",
   "metadata": {},
   "source": [
    "## 3) Fix dates & basic schema\n",
    "The `event_date` has mixed formats. We'll coerce to datetime safely; invalid ones become `NaT`.\n",
    "\n",
    "## 3) Corrigindo datas e esquema básico\r\n",
    "A coluna `event_date` possui formatos mistos. Vamos converter para datetime de forma segura; valores inválidos se tornarão `NaT` (Not a Time).\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ce49450-a08a-4855-8b4f-bc2f58e87d20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-04-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-12-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-09-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-04-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-03-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-07-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023-01-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023-04-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2023-05-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2023-08-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  event_date\n",
       "0 2023-04-13\n",
       "1 2023-12-15\n",
       "2 2023-09-28\n",
       "3 2023-04-17\n",
       "4 2023-03-13\n",
       "5 2023-07-08\n",
       "6 2023-01-21\n",
       "7 2023-04-13\n",
       "8 2023-05-02\n",
       "9 2023-08-03"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['event_date'] = pd.to_datetime(df['event_date'], errors='coerce')# tenta converter cada valor para datetime; se não conseguir, coloca NaT.\n",
    "df[['event_date']].head(10)# mostra as primeiras linhas da coluna convertida para checar se a conversão funcionou."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f247457f",
   "metadata": {},
   "source": [
    "## 4) Feature engineering from dates\n",
    "Create features like `event_month`, `event_dayofweek`, and `recency_days` (relative to dataset max date).\n",
    "\n",
    "## 4) Criação de features a partir de datas\r\n",
    "Vamos criar novas features, como `event_month`, `event_dayofweek` e `recency_days` (relativa à data máxima do dataset)features\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81537c45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_date</th>\n",
       "      <th>event_month</th>\n",
       "      <th>event_day_of_week</th>\n",
       "      <th>recency_days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-04-13</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>297.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-12-15</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-09-28</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>129.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-04-17</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>293.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-03-13</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>328.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  event_date  event_month  event_day_of_week  recency_days\n",
       "0 2023-04-13          4.0                3.0         297.0\n",
       "1 2023-12-15         12.0                4.0          51.0\n",
       "2 2023-09-28          9.0                3.0         129.0\n",
       "3 2023-04-17          4.0                0.0         293.0\n",
       "4 2023-03-13          3.0                0.0         328.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_date = df['event_date'].max()  # encontra a data máxima do dataset\n",
    "df['event_month'] = df['event_date'].dt.month  # mês do evento\n",
    "df['event_day_of_week'] = df['event_date'].dt.dayofweek  # dia da semana do evento (0=segunda, 6=domingo)\n",
    "df['recency_days'] = (max_date - df['event_date']).dt.days  # diferença em dias em relação à data máxima\n",
    "\n",
    "df[['event_date','event_month','event_day_of_week','recency_days']].head()  # mostra as primeiras linhas das novas features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7c11f8",
   "metadata": {},
   "source": [
    "## 5) Split features & target\n",
    "We'll predict `churn` as the target. Identify numeric vs categorical columns.\n",
    "\n",
    "## 5) Separando features e target\r\n",
    "Nosso objetivo srr á **prever `churn`** como variável alvo (target).  \r\n",
    "Vamos também identificar **colunas numéricas** e **colunas categóricas*\n",
    "\n",
    " diretamente**.\r\n",
    "*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77ef3744",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>gender</th>\n",
       "      <th>region</th>\n",
       "      <th>purchases</th>\n",
       "      <th>category</th>\n",
       "      <th>event_month</th>\n",
       "      <th>event_day_of_week</th>\n",
       "      <th>recency_days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>34.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Female</td>\n",
       "      <td>East</td>\n",
       "      <td>2.0</td>\n",
       "      <td>D</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>297.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>40.0</td>\n",
       "      <td>54770.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>East</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85399.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>East</td>\n",
       "      <td>2.0</td>\n",
       "      <td>B</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>129.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>44.0</td>\n",
       "      <td>52703.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>293.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53504.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>North</td>\n",
       "      <td>7.0</td>\n",
       "      <td>B</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>328.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   age   income  gender region  purchases category  event_month  \\\n",
       "0   1  34.0      NaN  Female   East        2.0        D          4.0   \n",
       "1   2  40.0  54770.0    Male   East        2.0      NaN         12.0   \n",
       "2   3   NaN  85399.0  Female   East        2.0        B          9.0   \n",
       "3   4  44.0  52703.0    Male    NaN        NaN        B          4.0   \n",
       "4   5   NaN  53504.0     NaN  North        7.0        B          3.0   \n",
       "\n",
       "   event_day_of_week  recency_days  \n",
       "0                3.0         297.0  \n",
       "1                4.0          51.0  \n",
       "2                3.0         129.0  \n",
       "3                0.0         293.0  \n",
       "4                0.0         328.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = 'churn'\n",
    "feature_cols = [c for c in df.columns if c not in [target]]  # todas as colunas, exceto a target\n",
    "X = df[feature_cols].copy()  # features\n",
    "y = df[target].copy()        # target\n",
    "\n",
    "# Colunas numéricas\n",
    "numeric_features = ['age','income','purchases','event_month','event_day_of_week','recency_days']\n",
    "\n",
    "# Colunas categóricas\n",
    "categorical_features = ['gender','region','category']\n",
    "\n",
    "# Colunas de data (serão descartadas após extrair features)\n",
    "date_cols = ['event_date']  \n",
    "\n",
    "# Remove a coluna de data bruta das features\n",
    "X = X.drop(columns=date_cols)\n",
    "\n",
    "X.head()  # mostra as primeiras linhas das features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d0b1fb-9e35-431e-8694-d884a0ea0833",
   "metadata": {},
   "source": [
    "### 🎯 Target\n",
    "\n",
    "- `churn` será a variável que queremos prever.  \n",
    "- `y` recebe apenas a coluna alvo.\n",
    "\n",
    "### 🧩 Features\n",
    "\n",
    "- `X` contém todas as colunas que serão usadas como entrada para o modelo.  \n",
    "- Aqui separamos manualmente **numéricas**, **categóricas** e **datas**.\n",
    "\n",
    "### 🗓️ Por que dropar `event_date`\n",
    "\n",
    "- Já extraímos informações relevantes da data:  \n",
    "  - `event_month`  \n",
    "  - `event_day_of_week`  \n",
    "  - `recency_days`  \n",
    "- A coluna bruta `event_date` **não é útil para ML diretamente**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb1d4db",
   "metadata": {},
   "source": [
    "## 6) Outlier exploration (numeric)\n",
    "Use Z-score/IQR to **detect** outliers before deciding to cap/winsorize.\n",
    "\n",
    "## 6) Exploração de outliers (colunas numéricas)\r\n",
    "\r\n",
    "Antes de decidir **como tratar outliers** (por exemplo, cap ou winsorize), vamos **identificá-los** usando Z-score/IQR.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03084138",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.012"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "# Seleciona apenas as features numéricas\n",
    "numX = X[numeric_features].copy()\n",
    "\n",
    "# Calcula o Z-score absoluto, ignorando NaNs\n",
    "z = np.abs(stats.zscore(numX, nan_policy='omit'))\n",
    "\n",
    "# Máscara para detectar linhas com pelo menos um outlier (Z-score > 3)\n",
    "outlier_mask = (z > 3).any(axis=1)\n",
    "\n",
    "# Taxa de outliers no dataset\n",
    "outlier_rate = outlier_mask.mean()\n",
    "outlier_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0963a6fa-6690-481a-9d31-d48646c4eb43",
   "metadata": {},
   "source": [
    "Explicação didática\n",
    "\n",
    "Z-score: mede quantos desvios-padrão cada valor está distante da média.\n",
    "\n",
    "Valores com |Z| > 3 são geralmente considerados outliers extremos.\n",
    "\n",
    "nan_policy='omit': ignora valores ausentes na hora de calcular o Z-score, evitando erros.\n",
    "\n",
    "outlier_mask: identifica quais linhas têm pelo menos um outlier.\n",
    "\n",
    "outlier_rate: mostra a proporção de linhas com outliers, ajudando a decidir se vamos tratar, remover ou deixar os outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d777bb2a-f787-4dc5-8ef9-30ffc3b63e33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "249d89ef",
   "metadata": {},
   "source": [
    "## 7) Preprocessing pipeline\n",
    "- **Impute** missing values (KNN for numeric; constant for categorical)\n",
    "- **Scale** numeric features\n",
    "- **One-hot encode** categoricals\n",
    "\n",
    "We’ll wrap everything in a scikit-learn **Pipeline** to avoid leakage and ensure repeatability.\n",
    "\n",
    "a tradução ficará abaixo do bloco do código, pois irá integrar uma explicação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03687751",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Split inicial (com estratificação para manter proporção de churn)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Transformações para colunas numéricas\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', KNNImputer(n_neighbors=3)),   # preenche valores ausentes usando vizinhos\n",
    "    ('scaler', StandardScaler())              # normaliza escala\n",
    "])\n",
    "\n",
    "# Transformações para colunas categóricas\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),  # preenche categorias ausentes\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))    # one-hot encoding\n",
    "])\n",
    "\n",
    "# Junta tudo em um pré-processador\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e540cd56-7d12-4b50-a0ad-1ffbcef44d5b",
   "metadata": {},
   "source": [
    "## 7) Pipeline de Pré-processamento\n",
    "\n",
    "- Imputação (preencher valores ausentes):\n",
    "- - Numéricos → KNNImputer (usa vizinhos próximos para preencher).\n",
    "  - Categóricos → SimpleImputer(strategy='most_frequent') (preenche com a categoria mais frequente).\n",
    "- Escalonamento (numeric):\n",
    "- - StandardScaler() → deixa cada feature com média 0 e desvio padrão 1.\n",
    "- Codificação one-hot (categorical):\n",
    "- - OneHotEncoder(handle_unknown='ignore') → transforma categorias em colunas binárias (0/1).\n",
    "  - O parâmetro handle_unknown='ignore' evita erro se aparecer uma nova categoria no teste que não existia no treino.\n",
    "- Tudo isso é empacotado em um Pipeline do scikit-learn, garantindo:\n",
    "- - ✅ Reprodutibilidade\n",
    "  - ✅ Nada do teste vaza para o treino\n",
    "  - ✅ Um único objeto controla todas as etapas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9183f491",
   "metadata": {},
   "source": [
    "### Optional: Outlier capping (winsorization)\n",
    "We can add a custom transformer to cap extreme values after imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e3c51b0-7e4a-4264-92ee-04a77146e22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa classes base para criar transformadores compatíveis com scikit-learn\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# Criação de um transformador chamado Winsorizer\n",
    "class Winsorizer(BaseEstimator, TransformerMixin):\n",
    "    # Inicializa o transformador definindo os limites inferior e superior (quantis)\n",
    "    def __init__(self, quantile_low=0.01, quantile_high=0.99):\n",
    "        self.quantile_low = quantile_low       # ex: 1º percentil\n",
    "        self.quantile_high = quantile_high     # ex: 99º percentil\n",
    "        self.lows_ = None                      # limites inferiores calculados\n",
    "        self.highs_ = None                     # limites superiores calculados\n",
    "\n",
    "    # Método de ajuste (fit): calcula os quantis com base nos dados\n",
    "    def fit(self, X, y=None):\n",
    "        import pandas as pd\n",
    "        X = pd.DataFrame(X)                               # garante que X seja DataFrame\n",
    "        self.lows_ = X.quantile(self.quantile_low)        # calcula o limite inferior\n",
    "        self.highs_ = X.quantile(self.quantile_high)      # calcula o limite superior\n",
    "        return self                                       # retorna o próprio objeto (padrão em sklearn)\n",
    "\n",
    "    # Método de transformação (transform): aplica a Winsorização\n",
    "    def transform(self, X):\n",
    "        import pandas as pd\n",
    "        X = pd.DataFrame(X)                               # garante que X seja DataFrame\n",
    "        # Trava valores abaixo do low e acima do high em cada coluna\n",
    "        X = X.clip(lower=self.lows_, upper=self.highs_, axis=1)\n",
    "        return X.values                                   # retorna como numpy array (compatível com sklearn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc99255c-6f99-468b-acf1-79a5411df636",
   "metadata": {},
   "source": [
    "# Extra - Devo sempre usar o Winsorizer?\n",
    "- Ao pesquisar se há diferença entre fazer na mão e usando o código winsorizer, não há quase diferenças e irei citar abaixo.\n",
    "\n",
    "## Diferença principal 🚨\n",
    "- Manual (clip): rápido, ótimo para análise exploratória e testes.\n",
    "- Classe (Winsorizer): segue o padrão do scikit-learn → encaixa em Pipeline, pode ser usado dentro de GridSearchCV, etc.\n",
    "\n",
    "Então depende do caso, como regras de negócio ou do problema abordado\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55fd042",
   "metadata": {},
   "source": [
    "## 8) Train a model with the preprocessing pipeline\n",
    "We’ll use Logistic Regression as a baseline to demonstrate how preprocessing and modeling fit together.\n",
    "\n",
    "## 8) Treine um modelo com o pipeline de pré-processamento\r\n",
    "Usaremos a Regressão Logística como linha de base para demonstrar como o pré-processamento e a modelagem se encaixam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0342aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6833\n",
      "ROC AUC: 0.5135\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      1.00      0.81       205\n",
      "           1       0.00      0.00      0.00        95\n",
      "\n",
      "    accuracy                           0.68       300\n",
      "   macro avg       0.34      0.50      0.41       300\n",
      "weighted avg       0.47      0.68      0.55       300\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report\n",
    "\n",
    "clf = Pipeline(steps=[('preprocess', preprocessor), ('model', LogisticRegression(max_iter=200))])\n",
    "# Cria um Pipeline com duas etapas:\n",
    "# 'preprocess': aplica o preprocessor que você definiu antes (ex.: normalização, one-hot encoding, imputação).\n",
    "# 'model': roda a regressão logística.\n",
    "# O max_iter=200 aumenta o número de iterações para garantir que o modelo convirja.\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "# Treina o pipeline inteiro:\n",
    "# O preprocessor aprende no X_train (ex.: média para imputação, colunas para OneHotEncoder).\n",
    "# A regressão logística é treinada nos dados transformados.\n",
    "\n",
    "preds = clf.predict(X_test) # preds: rótulos 0 ou 1 previstos.\n",
    "probs = clf.predict_proba(X_test)[:,1] # probs: probabilidades da classe positiva ([:,1] pega só a coluna referente à classe 1).\n",
    "\n",
    "acc = accuracy_score(y_test, preds) # acc: porcentagem de acertos.\n",
    "auc = roc_auc_score(y_test, probs) # auc: métrica que avalia a capacidade do modelo em separar classes (independente de threshold fixo).\n",
    "\n",
    "print(\"Accuracy:\", round(acc, 4))\n",
    "print(\"ROC AUC:\", round(auc, 4))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87455ad8-5c5b-4d57-a2fc-d47bee326eda",
   "metadata": {},
   "source": [
    "⚠️ **UndefinedMetricWarning**  \r\n",
    "Esse aviso aparece quando uma **classe do dataset não foi prevista pelo modelo**.  \r\n",
    "Exemplo: se a classe `1` existe nos dados, mas o modelo só previu `0`, a precisão para `1` não pode ser calculada → é definida como `0.0`.  \r\n",
    "\r\n",
    "👉 Isso geralmente indica **desbalanceamento de classes** ou que o modelo não está aprendendo a distinguir bem essa classe.  \r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319eeb3d",
   "metadata": {},
   "source": [
    "### Compare with winsorization variant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dec22372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Winsorized Accuracy: 0.6833\n",
      "Winsorized ROC AUC: 0.5135\n"
     ]
    }
   ],
   "source": [
    "# Criação de um Pipeline que combina pré-processamento e modelo\n",
    "clf_w = Pipeline(steps=[\n",
    "    ('preprocess', preprocessor),            # etapa de pré-processamento (ex: normalização, one-hot encoding, etc.)\n",
    "    ('model', LogisticRegression(max_iter=200))  # modelo de Regressão Logística com até 200 iterações para convergir\n",
    "])\n",
    "\n",
    "# Treinamento do modelo com os dados de treino\n",
    "clf_w.fit(X_train, y_train)\n",
    "\n",
    "# Predição nos dados de teste:\n",
    "# - preds_w: classes previstas (0 ou 1)\n",
    "# - probs_w: probabilidades previstas para a classe positiva (coluna índice 1)\n",
    "preds_w = clf_w.predict(X_test)\n",
    "probs_w = clf_w.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Cálculo das métricas:\n",
    "# - Accuracy: porcentagem de acertos\n",
    "# - ROC AUC: mede quão bem o modelo separa as classes (robusta em cenários desbalanceados)\n",
    "acc_w = accuracy_score(y_test, preds_w)\n",
    "auc_w = roc_auc_score(y_test, probs_w)\n",
    "\n",
    "# Impressão dos resultados já arredondados para 4 casas decimais\n",
    "print(\"Winsorized Accuracy:\", round(acc_w, 4))\n",
    "print(\"Winsorized ROC AUC:\", round(auc_w, 4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd81cc46-117f-4968-900b-b85f423fe263",
   "metadata": {},
   "source": [
    "###  ⁇  Why use `class_weight='balanced'`?\r\n",
    "The parameter `class_weight='balanced'` in Logistic Regression automatically adjusts class weights **based on their frequency in the dataset**.  \n",
    "- If class `1` is rare, it gets a higher weight during training.  \n",
    "- This forces the model to pay more attention to the minority class, reducing the risk of predicting only the majority class.  \n",
    "\n",
    "⚠️ Note: this doesn’t fully solve imbalance, but it **partially improves the situation**. The model treats classes more fairly, although overall *accuracy* might slightly drop.  \n",
    "Often, additional techniques such as **oversampling, undersampling, or decision threshold tuning** are still required.\n",
    "\n",
    "\r\n",
    "##⚖️ Por que usar `class_weight='balanced'`?ês\r\n",
    "O parâmetro `class_weight='balanced'` na Regressão Logística ajusta automaticamente os pesos das classes **de acordo com sua frequência no dataset**.  \r\n",
    "- Se a classe `1` é rara, ela recebe mais peso no treinamento.  \r\n",
    "- Isso força o modelo a prestar mais atenção nela, reduzindo o risco de prever apenas a classe majoritária.  \r\n",
    "\r\n",
    "⚠️ Importante: isso não resolve totalmente o desbalanceamento, mas **ajuda parcialmente**. O modelo passa a considerar as classes de forma mais justa, embora possa perder um pouco em *accuracy*.  \r\n",
    "Em muitos casos, outras técnicas como **oversampling, undersampling ou ajuste de limiar de decisão** ainda são necessárias\n",
    "---e still required.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "482531ea-6139-47ca-aae5-5287c5107fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5367\n",
      "ROC AUC: 0.5149\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.56      0.62       205\n",
      "           1       0.34      0.48      0.40        95\n",
      "\n",
      "    accuracy                           0.54       300\n",
      "   macro avg       0.52      0.52      0.51       300\n",
      "weighted avg       0.59      0.54      0.55       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report\n",
    "\n",
    "# Definição do modelo de Regressão Logística dentro de um Pipeline\n",
    "# - 'preprocess': aplica o pré-processamento definido anteriormente (ex: normalização, codificação, etc.)\n",
    "# - 'model': cria a Regressão Logística\n",
    "#   - max_iter=200: define o número máximo de iterações do otimizador (padrão é 100, aqui aumentamos para evitar não convergir)\n",
    "#   - class_weight='balanced': ajusta os pesos automaticamente para lidar com desbalanceamento de classes\n",
    "clf = Pipeline(steps=[\n",
    "    ('preprocess', preprocessor),\n",
    "    ('model', LogisticRegression(max_iter=200, class_weight='balanced'))\n",
    "])\n",
    "\n",
    "# Treinamento do modelo com os dados de treino\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predições do modelo:\n",
    "# - preds: predição final (classe 0 ou 1)\n",
    "# - probs: probabilidade prevista para a classe positiva (classe 1)\n",
    "preds = clf.predict(X_test)\n",
    "probs = clf.predict_proba(X_test)[:, 1]  # Pega apenas a coluna da classe positiva\n",
    "\n",
    "# Avaliação do modelo:\n",
    "# - Accuracy: proporção de acertos sobre todas as amostras\n",
    "# - ROC AUC: mede a capacidade do modelo em distinguir entre classes (quanto mais perto de 1, melhor)\n",
    "acc = accuracy_score(y_test, preds)\n",
    "auc = roc_auc_score(y_test, probs)\n",
    "\n",
    "# Impressão dos resultados:\n",
    "# - Accuracy arredondado em 4 casas decimais\n",
    "# - ROC AUC arredondado em 4 casas decimais\n",
    "# - Classification Report: mostra precisão, recall, f1-score e suporte para cada classe\n",
    "#   - zero_division=0 evita erros caso alguma métrica não possa ser calculada (ex: divisão por zero em recall)\n",
    "print(\"Accuracy:\", round(acc, 4))\n",
    "print(\"ROC AUC:\", round(auc, 4))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, preds, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58b9fdc-442c-4a05-9ab3-9f74e4ff41e2",
   "metadata": {},
   "source": [
    "## Antes (class_weight default)\n",
    "\n",
    "- Classe 1 (churn):\n",
    "- precision: 0.00\n",
    "- recall: 0.00\n",
    "- f1: 0.00\n",
    "\n",
    "O modelo não previa nenhum churn.\n",
    "\n",
    "## Depois (class_weight='balanced')\n",
    "\n",
    "- Classe 1 (churn):\n",
    "- precision: 0.34\n",
    "- recall: 0.48\n",
    "- f1: 0.40\n",
    "\n",
    "Ou seja: ele erra bastante, mas finalmente começa a prever churn.\n",
    "\n",
    "### 👉 O accuracy caiu de ~0.68 → ~0.54, mas isso é esperado:\n",
    "\n",
    "Antes, ele só dizia \"todo mundo é 0\" e ganhava accuracy alto \"de graça\".\n",
    "\n",
    "- Agora, ele tenta acertar os churns (classe difícil e minoritária).\n",
    "e isso foi graças a LogisticRegression(max_iter=200, class_weight='balanced')\n",
    "claro está longe do ideal mas agora o já vimos um progresso\r\n",
    "e pelo que pesquisei da para usar  técnicas de oversampling/undersampling (SMOTE, etc. para tentarmos melhorar a qualidade da previsão.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f4d0bb",
   "metadata": {},
   "source": [
    "## 9) Export the preprocessing pipeline\n",
    "Save the fitted preprocessor + model for reuse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8289c8cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Artifacts saved'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(clf, 'ml_prep_pipeline_baseline.joblib')\n",
    "joblib.dump(clf_w, 'ml_prep_pipeline_winsor.joblib')\n",
    "'Artifacts saved'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba49411f-8a8e-4c78-a50e-c8cf819174af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
